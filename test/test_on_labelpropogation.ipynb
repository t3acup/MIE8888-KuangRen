{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-20T07:48:36.694715Z",
     "start_time": "2025-07-20T07:48:30.757678Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    normalized_mutual_info_score,\n",
    "    f1_score,\n",
    "    accuracy_score,\n",
    "    recall_score\n",
    ")\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T07:48:39.400436Z",
     "start_time": "2025-07-20T07:48:39.391206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EMBEDDING_FILES = [\n",
    "    \"embeddings\\java_CodeBERT_embeddings.pkl\",\n",
    "    \"embeddings\\java_GraphCodeBERT_embeddings.pkl\",\n",
    "    \"embeddings\\java_UniXcoder_embeddings.pkl\",\n",
    "    \"embeddings\\java_CodeT5_embeddings.pkl\",\n",
    "    \"embeddings\\java_InCoder_embeddings.pkl\"\n",
    "]\n",
    "LABEL_COUNTS = [5, 10, 25, 50]\n",
    "SEED = 42\n",
    "REPEATS = 5 "
   ],
   "id": "966f81bab5673af0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T07:48:40.934818Z",
     "start_time": "2025-07-20T07:48:40.919838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_label_propagation(embeddings, labels, num_labels_per_class, repeats=5, seed=SEED):\n",
    "    unique_labels = np.unique(labels)\n",
    "    n_classes = len(unique_labels)\n",
    "\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=repeats, train_size=num_labels_per_class * n_classes, random_state=seed\n",
    "    )\n",
    "\n",
    "    ari_scores, nmi_scores = [], []\n",
    "    f1_scores, acc_scores, recall_scores = [], [], []\n",
    "\n",
    "    for train_index, _ in sss.split(embeddings, labels):\n",
    "        y_partial = -np.ones(len(labels))\n",
    "        y_partial[train_index] = labels[train_index]\n",
    "\n",
    "        model = LabelPropagation(kernel='rbf', gamma=20, max_iter=1000)\n",
    "        model.fit(embeddings, y_partial)\n",
    "        pred = model.transduction_\n",
    "\n",
    "        ari_scores.append(adjusted_rand_score(labels, pred))\n",
    "        nmi_scores.append(normalized_mutual_info_score(labels, pred))\n",
    "        f1_scores.append(f1_score(labels, pred, average='macro'))\n",
    "        acc_scores.append(accuracy_score(labels, pred))\n",
    "        recall_scores.append(recall_score(labels, pred, average='macro'))\n",
    "\n",
    "    # Store all metrics\n",
    "    metrics = {\n",
    "        'ARI': (np.mean(ari_scores), np.std(ari_scores)),\n",
    "        'NMI': (np.mean(nmi_scores), np.std(nmi_scores)),\n",
    "        'F1': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "        'Accuracy': (np.mean(acc_scores), np.std(acc_scores)),\n",
    "        'Recall': (np.mean(recall_scores), np.std(recall_scores))\n",
    "    }\n",
    "\n",
    "    return metrics"
   ],
   "id": "1f8e5e691a849dad",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T07:49:10.983253Z",
     "start_time": "2025-07-20T07:48:44.216083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = {}\n",
    "\n",
    "for file in EMBEDDING_FILES:\n",
    "    df = pd.read_pickle(file)\n",
    "    X = np.vstack(df[\"embedding\"].values)\n",
    "    y = pd.factorize(df[\"cluster\"])[0]  # convert clusters to int labels\n",
    "\n",
    "    model_name = file.split(\"_\")[1]\n",
    "    results[model_name] = {}\n",
    "\n",
    "    print(f\"\\nEvaluating: {model_name}\")\n",
    "\n",
    "    for k in LABEL_COUNTS:\n",
    "        print(f\"→ {k} samples per cluster\")\n",
    "        metrics = evaluate_label_propagation(X, y, num_labels_per_class=k)\n",
    "\n",
    "        # Unpack metrics into results dict\n",
    "        results[model_name][k] = {\n",
    "            metric: (mean, std) for metric, (mean, std) in metrics.items()\n",
    "        }\n",
    "\n",
    "        # Print summary\n",
    "        print(\" | \".join(\n",
    "            f\"{metric}: {mean:.3f} ± {std:.3f}\"\n",
    "            for metric, (mean, std) in results[model_name][k].items()\n",
    "        ))"
   ],
   "id": "5fdbf556a13d40d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: CodeBERT\n",
      "→ 5 samples per cluster\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 15\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m LABEL_COUNTS:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m→ \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples per cluster\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 15\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_label_propagation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_labels_per_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m# Unpack metrics into results dict\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     results[model_name][k] \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     19\u001B[0m         metric: (mean, std) \u001B[38;5;28;01mfor\u001B[39;00m metric, (mean, std) \u001B[38;5;129;01min\u001B[39;00m metrics\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m     20\u001B[0m     }\n",
      "Cell \u001B[1;32mIn[3], line 17\u001B[0m, in \u001B[0;36mevaluate_label_propagation\u001B[1;34m(embeddings, labels, num_labels_per_class, repeats, seed)\u001B[0m\n\u001B[0;32m     14\u001B[0m y_partial[train_index] \u001B[38;5;241m=\u001B[39m labels[train_index]\n\u001B[0;32m     16\u001B[0m model \u001B[38;5;241m=\u001B[39m LabelPropagation(kernel\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrbf\u001B[39m\u001B[38;5;124m'\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43membeddings\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_partial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtransduction_\n\u001B[0;32m     20\u001B[0m ari_scores\u001B[38;5;241m.\u001B[39mappend(adjusted_rand_score(labels, pred))\n",
      "File \u001B[1;32mC:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:490\u001B[0m, in \u001B[0;36mLabelPropagation.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, y):\n\u001B[0;32m    472\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Fit a semi-supervised label propagation model to X.\u001B[39;00m\n\u001B[0;32m    473\u001B[0m \n\u001B[0;32m    474\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    488\u001B[0m \u001B[38;5;124;03m        Returns the instance itself.\u001B[39;00m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 490\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\base.py:1389\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1382\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1384\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1385\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1386\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1387\u001B[0m     )\n\u001B[0;32m   1388\u001B[0m ):\n\u001B[1;32m-> 1389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mC:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:307\u001B[0m, in \u001B[0;36mBaseLabelPropagation.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m    306\u001B[0m l_previous \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_distributions_\n\u001B[1;32m--> 307\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_distributions_ \u001B[38;5;241m=\u001B[39m \u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    308\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgraph_matrix\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel_distributions_\u001B[49m\n\u001B[0;32m    309\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    311\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variant \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpropagation\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    312\u001B[0m     normalizer \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabel_distributions_, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[:, np\u001B[38;5;241m.\u001B[39mnewaxis]\n",
      "File \u001B[1;32mC:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:203\u001B[0m, in \u001B[0;36msafe_sparse_dot\u001B[1;34m(a, b, dense_output)\u001B[0m\n\u001B[0;32m    201\u001B[0m         ret \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mtensordot(a, b, axes\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, b_axis])\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 203\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43ma\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    206\u001B[0m     sparse\u001B[38;5;241m.\u001B[39missparse(a)\n\u001B[0;32m    207\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(b)\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m dense_output\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ret, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoarray\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    210\u001B[0m ):\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39mtoarray()\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## active learning",
   "id": "310ad80f8f00864d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T02:35:17.105657Z",
     "start_time": "2025-07-02T02:35:17.083906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import entropy\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "def simulate_active_learning(\n",
    "    X, y, strategy=\"entropy\", initial_labels_per_class=5,\n",
    "        total_labeled_targets_lst = [100, 250, 500], seed=SEED\n",
    "):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n_classes = len(np.unique(y))\n",
    "    total_samples = len(y)\n",
    "\n",
    "    # === Initialize labeled set ===\n",
    "    labeled_mask = np.zeros(total_samples, dtype=bool)\n",
    "    for cls in range(n_classes):\n",
    "        cls_indices = np.where(y == cls)[0]\n",
    "        labeled_indices = rng.choice(cls_indices, initial_labels_per_class, replace=False)\n",
    "        labeled_mask[labeled_indices] = True\n",
    "\n",
    "    y_partial = -np.ones(total_samples)\n",
    "    y_partial[labeled_mask] = y[labeled_mask]\n",
    "\n",
    "    all_metrics = []\n",
    "    queried = labeled_mask.sum()\n",
    "    batch_sizes = [10, 30, 50]\n",
    "    batch_idx = 0\n",
    "    \n",
    "    while queried < total_labeled_targets_lst[-1]:\n",
    "        batch_size = batch_sizes[min(batch_idx, len(batch_sizes) - 1)]\n",
    "        model = LabelPropagation(kernel='rbf', gamma=20, max_iter=1000)\n",
    "        model.fit(X, y_partial)\n",
    "        probs = model.label_distributions_\n",
    "\n",
    "        # === Sampling Strategy ===\n",
    "        if strategy == \"entropy\":\n",
    "            score = entropy(probs.T)\n",
    "        elif strategy == \"euclidean_distance\":\n",
    "            labeled_X = X[labeled_mask]\n",
    "            dist = euclidean_distances(X, labeled_X)\n",
    "            score = dist.min(axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid strategy.\")\n",
    "\n",
    "        unlabeled_indices = np.where(~labeled_mask)[0]\n",
    "        query_indices = unlabeled_indices[np.argsort(score[unlabeled_indices])[-batch_size:]]\n",
    "        labeled_mask[query_indices] = True\n",
    "        y_partial[query_indices] = y[query_indices]\n",
    "        queried += batch_size\n",
    "        \n",
    "        if queried in total_labeled_targets_lst:\n",
    "            batch_idx+=1\n",
    "            # Final evaluation at current target\n",
    "            pred = model.transduction_\n",
    "            metrics = {\n",
    "                \"Labeled\": queried,\n",
    "                \"ARI\": adjusted_rand_score(y, pred),\n",
    "                \"NMI\": normalized_mutual_info_score(y, pred),\n",
    "                \"Accuracy\": accuracy_score(y, pred),\n",
    "                \"F1\": f1_score(y, pred, average=\"macro\"),\n",
    "                \"Recall\": recall_score(y, pred, average=\"macro\")\n",
    "            }\n",
    "            all_metrics.append(metrics)\n",
    "\n",
    "    return all_metrics"
   ],
   "id": "d2ec465f67b433a1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T04:31:43.672709Z",
     "start_time": "2025-07-02T04:10:44.692710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_labeled_targets = [100, 250, 500]\n",
    "\n",
    "# CodeBERT\n",
    "file = \"embeddings\\java_CodeBERT_embeddings.pkl\"\n",
    "\n",
    "df = pd.read_pickle(file)\n",
    "X = np.vstack(df[\"embedding\"].values)\n",
    "y = pd.factorize(df[\"cluster\"])[0]\n",
    "\n",
    "model_name = file.split(\"_\")[1]\n",
    "results[model_name] = {}\n",
    "    \n",
    "print(f\"\\nEvaluating: {model_name}\")\n",
    "al_entropy = simulate_active_learning(X, y, strategy=\"entropy\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "al_distance = simulate_active_learning(X, y, strategy=\"euclidean_distance\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "    \n",
    "for i, total_k in enumerate(total_labeled_targets):\n",
    "    print(f\"Active Learning with total samples of {total_k} (Entropy): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_entropy[i].items() if k != \"Labeled\"\n",
    "    ))\n",
    "    \n",
    "    print(f\"Active Learning with total samples of {total_k} (Euclidean Distance): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_distance[i].items() if k != \"Labeled\"\n",
    "    ))"
   ],
   "id": "48b26e5edc1b5ea0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: CodeBERT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Learning with total samples of 100 (Entropy): ARI: 0.332 | NMI: 0.471 | Accuracy: 0.582 | F1: 0.589 | Recall: 0.580\n",
      "Active Learning with total samples of 100 (Euclidean Distance): ARI: 0.288 | NMI: 0.428 | Accuracy: 0.537 | F1: 0.544 | Recall: 0.535\n",
      "Active Learning with total samples of 250 (Entropy): ARI: 0.337 | NMI: 0.464 | Accuracy: 0.596 | F1: 0.583 | Recall: 0.587\n",
      "Active Learning with total samples of 250 (Euclidean Distance): ARI: 0.315 | NMI: 0.450 | Accuracy: 0.562 | F1: 0.565 | Recall: 0.562\n",
      "Active Learning with total samples of 500 (Entropy): ARI: 0.367 | NMI: 0.483 | Accuracy: 0.625 | F1: 0.619 | Recall: 0.624\n",
      "Active Learning with total samples of 500 (Euclidean Distance): ARI: 0.353 | NMI: 0.494 | Accuracy: 0.598 | F1: 0.602 | Recall: 0.600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T04:32:00.769127Z",
     "start_time": "2025-07-02T04:31:43.795721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# GraphCodeBERT\n",
    "file = \"embeddings\\java_GraphCodeBERT_embeddings.pkl\"\n",
    "\n",
    "df = pd.read_pickle(file)\n",
    "X = np.vstack(df[\"embedding\"].values)\n",
    "y = pd.factorize(df[\"cluster\"])[0]\n",
    "\n",
    "model_name = file.split(\"_\")[1]\n",
    "results[model_name] = {}\n",
    "    \n",
    "print(f\"\\nEvaluating: {model_name}\")\n",
    "al_entropy = simulate_active_learning(X, y, strategy=\"entropy\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "al_distance = simulate_active_learning(X, y, strategy=\"euclidean_distance\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "    \n",
    "for i, total_k in enumerate(total_labeled_targets):\n",
    "    print(f\"Active Learning with total samples of {total_k} (Entropy): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_entropy[i].items() if k != \"Labeled\"\n",
    "    ))\n",
    "    \n",
    "    print(f\"Active Learning with total samples of {total_k} (Euclidean Distance): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_distance[i].items() if k != \"Labeled\"\n",
    "    ))"
   ],
   "id": "4a01dd574e1c669e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: GraphCodeBERT\n",
      "Active Learning with total samples of 100 (Entropy): ARI: 0.143 | NMI: 0.515 | Accuracy: 0.497 | F1: 0.542 | Recall: 0.507\n",
      "Active Learning with total samples of 100 (Euclidean Distance): ARI: 0.067 | NMI: 0.392 | Accuracy: 0.386 | F1: 0.424 | Recall: 0.388\n",
      "Active Learning with total samples of 250 (Entropy): ARI: 0.570 | NMI: 0.784 | Accuracy: 0.797 | F1: 0.817 | Recall: 0.804\n",
      "Active Learning with total samples of 250 (Euclidean Distance): ARI: 0.083 | NMI: 0.428 | Accuracy: 0.421 | F1: 0.469 | Recall: 0.426\n",
      "Active Learning with total samples of 500 (Entropy): ARI: 0.967 | NMI: 0.973 | Accuracy: 0.981 | F1: 0.976 | Recall: 0.982\n",
      "Active Learning with total samples of 500 (Euclidean Distance): ARI: 0.114 | NMI: 0.477 | Accuracy: 0.471 | F1: 0.521 | Recall: 0.474\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T04:32:15.593153Z",
     "start_time": "2025-07-02T04:32:00.785357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# UniXcoder\n",
    "file = \"embeddings\\java_UniXcoder_embeddings.pkl\"\n",
    "\n",
    "df = pd.read_pickle(file)\n",
    "X = np.vstack(df[\"embedding\"].values)\n",
    "y = pd.factorize(df[\"cluster\"])[0]\n",
    "\n",
    "model_name = file.split(\"_\")[1]\n",
    "results[model_name] = {}\n",
    "    \n",
    "print(f\"\\nEvaluating: {model_name}\")\n",
    "al_entropy = simulate_active_learning(X, y, strategy=\"entropy\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "al_distance = simulate_active_learning(X, y, strategy=\"euclidean_distance\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "    \n",
    "for i, total_k in enumerate(total_labeled_targets):\n",
    "    print(f\"Active Learning with total samples of {total_k} (Entropy): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_entropy[i].items() if k != \"Labeled\"\n",
    "    ))\n",
    "    \n",
    "    print(f\"Active Learning with total samples of {total_k} (Euclidean Distance): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_distance[i].items() if k != \"Labeled\"\n",
    "    ))"
   ],
   "id": "88d0225c010c8aaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: UniXcoder\n",
      "Active Learning with total samples of 100 (Entropy): ARI: 0.134 | NMI: 0.498 | Accuracy: 0.475 | F1: 0.509 | Recall: 0.470\n",
      "Active Learning with total samples of 100 (Euclidean Distance): ARI: 0.045 | NMI: 0.345 | Accuracy: 0.347 | F1: 0.390 | Recall: 0.355\n",
      "Active Learning with total samples of 250 (Entropy): ARI: 0.716 | NMI: 0.840 | Accuracy: 0.866 | F1: 0.867 | Recall: 0.856\n",
      "Active Learning with total samples of 250 (Euclidean Distance): ARI: 0.053 | NMI: 0.372 | Accuracy: 0.374 | F1: 0.424 | Recall: 0.381\n",
      "Active Learning with total samples of 500 (Entropy): ARI: 0.969 | NMI: 0.975 | Accuracy: 0.982 | F1: 0.977 | Recall: 0.983\n",
      "Active Learning with total samples of 500 (Euclidean Distance): ARI: 0.077 | NMI: 0.428 | Accuracy: 0.434 | F1: 0.490 | Recall: 0.437\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:00:23.019901Z",
     "start_time": "2025-07-02T04:32:15.609009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CodeT5\n",
    "file = \"embeddings\\java_CodeT5_embeddings.pkl\"\n",
    "\n",
    "df = pd.read_pickle(file)\n",
    "X = np.vstack(df[\"embedding\"].values)\n",
    "y = pd.factorize(df[\"cluster\"])[0]\n",
    "\n",
    "model_name = file.split(\"_\")[1]\n",
    "results[model_name] = {}\n",
    "    \n",
    "print(f\"\\nEvaluating: {model_name}\")\n",
    "al_entropy = simulate_active_learning(X, y, strategy=\"entropy\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "al_distance = simulate_active_learning(X, y, strategy=\"euclidean_distance\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "    \n",
    "for i, total_k in enumerate(total_labeled_targets):\n",
    "    print(f\"Active Learning with total samples of {total_k} (Entropy): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_entropy[i].items() if k != \"Labeled\"\n",
    "    ))\n",
    "    \n",
    "    print(f\"Active Learning with total samples of {total_k} (Euclidean Distance): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_distance[i].items() if k != \"Labeled\"\n",
    "    ))"
   ],
   "id": "11601d5157e9a319",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: CodeT5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n",
      "C:\\study\\MIE8888\\.venv\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:324: ConvergenceWarning: max_iter=1000 was reached without convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Learning with total samples of 100 (Entropy): ARI: 0.350 | NMI: 0.492 | Accuracy: 0.595 | F1: 0.587 | Recall: 0.594\n",
      "Active Learning with total samples of 100 (Euclidean Distance): ARI: 0.343 | NMI: 0.473 | Accuracy: 0.598 | F1: 0.591 | Recall: 0.596\n",
      "Active Learning with total samples of 250 (Entropy): ARI: 0.352 | NMI: 0.498 | Accuracy: 0.593 | F1: 0.585 | Recall: 0.593\n",
      "Active Learning with total samples of 250 (Euclidean Distance): ARI: 0.372 | NMI: 0.509 | Accuracy: 0.627 | F1: 0.627 | Recall: 0.627\n",
      "Active Learning with total samples of 500 (Entropy): ARI: 0.468 | NMI: 0.582 | Accuracy: 0.679 | F1: 0.668 | Recall: 0.675\n",
      "Active Learning with total samples of 500 (Euclidean Distance): ARI: 0.437 | NMI: 0.565 | Accuracy: 0.671 | F1: 0.675 | Recall: 0.671\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T05:01:41.901985Z",
     "start_time": "2025-07-02T05:00:23.052555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# InCoder\n",
    "file = \"embeddings\\java_InCoder_embeddings.pkl\"\n",
    "\n",
    "df = pd.read_pickle(file)\n",
    "X = np.vstack(df[\"embedding\"].values)\n",
    "y = pd.factorize(df[\"cluster\"])[0]\n",
    "\n",
    "model_name = file.split(\"_\")[1]\n",
    "results[model_name] = {}\n",
    "    \n",
    "print(f\"\\nEvaluating: {model_name}\")\n",
    "al_entropy = simulate_active_learning(X, y, strategy=\"entropy\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "al_distance = simulate_active_learning(X, y, strategy=\"euclidean_distance\", total_labeled_targets_lst=total_labeled_targets, seed=SEED)\n",
    "    \n",
    "for i, total_k in enumerate(total_labeled_targets):\n",
    "    print(f\"Active Learning with total samples of {total_k} (Entropy): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_entropy[i].items() if k != \"Labeled\"\n",
    "    ))\n",
    "    \n",
    "    print(f\"Active Learning with total samples of {total_k} (Euclidean Distance): \" + \" | \".join(\n",
    "        f\"{k}: {v:.3f}\" for k, v in al_distance[i].items() if k != \"Labeled\"\n",
    "    ))"
   ],
   "id": "bdb79632af72feea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating: InCoder\n",
      "Active Learning with total samples of 100 (Entropy): ARI: 0.537 | NMI: 0.651 | Accuracy: 0.744 | F1: 0.736 | Recall: 0.742\n",
      "Active Learning with total samples of 100 (Euclidean Distance): ARI: 0.534 | NMI: 0.649 | Accuracy: 0.737 | F1: 0.728 | Recall: 0.733\n",
      "Active Learning with total samples of 250 (Entropy): ARI: 0.589 | NMI: 0.686 | Accuracy: 0.777 | F1: 0.772 | Recall: 0.776\n",
      "Active Learning with total samples of 250 (Euclidean Distance): ARI: 0.551 | NMI: 0.665 | Accuracy: 0.748 | F1: 0.739 | Recall: 0.746\n",
      "Active Learning with total samples of 500 (Entropy): ARI: 0.667 | NMI: 0.740 | Accuracy: 0.823 | F1: 0.816 | Recall: 0.821\n",
      "Active Learning with total samples of 500 (Euclidean Distance): ARI: 0.626 | NMI: 0.720 | Accuracy: 0.788 | F1: 0.777 | Recall: 0.780\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
